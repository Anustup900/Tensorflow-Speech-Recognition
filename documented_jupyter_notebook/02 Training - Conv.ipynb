{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Training - Conv\n",
    "#### Author: Jayant Verma\n",
    "#### Cognibit Solutions LLP\n",
    "\n",
    "Convolutional model training notebook. (Baseline Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metal_geek/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(\"../libs\")\n",
    "from classification import input_data\n",
    "from classification import models\n",
    "from classification import trainer\n",
    "from classification import freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the data folder to use the required data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags=tf.app.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags=tf.app.flags\n",
    "#Important Directories\n",
    "flags.DEFINE_string('data_dir','../data/raw','Train Data Folder')\n",
    "flags.DEFINE_string('summaries_dir','../summaries','Summaries Folder')\n",
    "flags.DEFINE_string('train_dir','../logs&checkpoint','Directory to write event logs and checkpoint')\n",
    "flags.DEFINE_string('models_dir','../models','Models Folder')\n",
    "#Task Specific Parameters\n",
    "flags.DEFINE_string('wanted_words','yes,no,up,down,left,right,on,off,stop,go','Wanted Words')\n",
    "flags.DEFINE_float('validation_percentage',10,'Validation Percentage')\n",
    "flags.DEFINE_float('testing_percentage',10,'Testing Percentage')\n",
    "flags.DEFINE_integer('sample_rate',16000,'Sample Rate')\n",
    "flags.DEFINE_integer('clip_duration_ms',1000,'Clip Duration in ms')\n",
    "flags.DEFINE_float('window_size_ms',30,'How long each spectogram timeslice is')\n",
    "flags.DEFINE_float('window_stride_ms',10.0,'How far to move in time between frequency windows.')\n",
    "flags.DEFINE_integer('dct_coefficient_count',40,'How many bins to use for the MFCC fingerprint')\n",
    "flags.DEFINE_float('time_shift_ms',100.0,'Range to randomly shift the training audio by in time.')\n",
    "\n",
    "FLAGS=flags.FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_architecture='conv'\n",
    "start_checkpoint=None\n",
    "logging_interval=1\n",
    "eval_step_interval=2000\n",
    "save_step_interval=1\n",
    "silence_percentage=10.0\n",
    "unknown_percentage=10.0\n",
    "background_frequency=0.8\n",
    "background_volume=0.1\n",
    "learning_rate='0.001,0.0001' #Always seperated by comma, trains with each of the learning rate for the given number of iterations\n",
    "train_steps='15000,300' #Declare  the training steps for which the learning rates will be used\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the get_train_data() get_val_data() and get_test_data() Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir=os.path.join(FLAGS.data_dir,'train','audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw/train/audio/*/*.wav\n",
      "../data/raw/train/audio/_background_noise_/dude_miaowing.wav\n",
      "../data/raw/train/audio/_background_noise_/doing_the_dishes.wav\n",
      "../data/raw/train/audio/_background_noise_/pink_noise.wav\n",
      "../data/raw/train/audio/_background_noise_/exercise_bike.wav\n",
      "../data/raw/train/audio/_background_noise_/running_tap.wav\n"
     ]
    }
   ],
   "source": [
    "model_settings = models.prepare_model_settings(\n",
    "      len(input_data.prepare_words_list(FLAGS.wanted_words.split(','))),\n",
    "      FLAGS.sample_rate, FLAGS.clip_duration_ms, FLAGS.window_size_ms,\n",
    "      FLAGS.window_stride_ms, FLAGS.dct_coefficient_count)\n",
    "audio_processor = input_data.AudioProcessor(\n",
    "      train_dir, silence_percentage, unknown_percentage,\n",
    "      FLAGS.wanted_words.split(','), FLAGS.validation_percentage,\n",
    "      FLAGS.testing_percentage, model_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(args):\n",
    "    sess=args\n",
    "    time_shift_samples = int((FLAGS.time_shift_ms * FLAGS.sample_rate) / 1000)\n",
    "    train_fingerprints, train_ground_truth = audio_processor.get_data(\n",
    "        batch_size, 0, model_settings,background_frequency,\n",
    "        background_volume, time_shift_samples, 'training', sess)\n",
    "    return train_fingerprints,train_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val_data(args):\n",
    "    '''\n",
    "    Input: (sess,offset)\n",
    "    '''\n",
    "    sess,i=args\n",
    "    validation_fingerprints, validation_ground_truth = (\n",
    "            audio_processor.get_data(batch_size, i, model_settings, 0.0,\n",
    "                                     0.0, 0, 'validation', sess))\n",
    "    return validation_fingerprints,validation_ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    sess=tf.InteractiveSession()\n",
    "    # Placeholders\n",
    "    fingerprint_size = model_settings['fingerprint_size']\n",
    "    label_count = model_settings['label_count']\n",
    "    fingerprint_input = tf.placeholder(\n",
    "      tf.float32, [None, fingerprint_size], name='fingerprint_input')\n",
    "    ground_truth_input = tf.placeholder(\n",
    "      tf.float32, [None, label_count], name='groundtruth_input')\n",
    "    set_size = audio_processor.set_size('validation')\n",
    "    label_count = model_settings['label_count']\n",
    "    # Create Model\n",
    "    \n",
    "    logits, dropout_prob = models.create_model(\n",
    "      fingerprint_input,\n",
    "      model_settings,\n",
    "      model_architecture,\n",
    "      is_training=True)\n",
    "    #Start Training\n",
    "    extra_args=(dropout_prob,label_count,batch_size,set_size)\n",
    "    trainer.train(sess,logits,fingerprint_input,ground_truth_input,get_train_data,\n",
    "                  get_val_data,train_steps,learning_rate,eval_step_interval, logging_interval=logging_interval,\n",
    "                  start_checkpoint=start_checkpoint,checkpoint_interval=save_step_interval,\n",
    "                  model_name=model_architecture,train_dir=FLAGS.train_dir,\n",
    "                  summaries_dir=FLAGS.summaries_dir,args=extra_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../src/libs/trainer.py:72: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "INFO:tensorflow:Training from step: 1 \n",
      "INFO:tensorflow:Step #1: rate 0.001000, accuracy 6.0%, cross entropy 2.506356\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-1\"\n",
      "INFO:tensorflow:Step #2: rate 0.001000, accuracy 8.0%, cross entropy 5.433812\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-2\"\n",
      "INFO:tensorflow:Step #3: rate 0.001000, accuracy 15.0%, cross entropy 2.397193\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-3\"\n",
      "INFO:tensorflow:Step #4: rate 0.001000, accuracy 13.0%, cross entropy 2.446571\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-4\"\n",
      "INFO:tensorflow:Step #5: rate 0.001000, accuracy 14.0%, cross entropy 2.463534\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-5\"\n",
      "INFO:tensorflow:Step #6: rate 0.001000, accuracy 14.0%, cross entropy 2.427137\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-6\"\n",
      "INFO:tensorflow:Step #7: rate 0.001000, accuracy 19.0%, cross entropy 2.387963\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-7\"\n",
      "INFO:tensorflow:Step #8: rate 0.001000, accuracy 15.0%, cross entropy 2.408651\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-8\"\n",
      "INFO:tensorflow:Step #9: rate 0.001000, accuracy 14.0%, cross entropy 2.367523\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-9\"\n",
      "INFO:tensorflow:Step #10: rate 0.001000, accuracy 8.0%, cross entropy 2.478460\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-10\"\n",
      "INFO:tensorflow:Step #11: rate 0.001000, accuracy 14.0%, cross entropy 2.411617\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-11\"\n",
      "INFO:tensorflow:Step #12: rate 0.001000, accuracy 13.0%, cross entropy 2.387878\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-12\"\n",
      "INFO:tensorflow:Step #13: rate 0.001000, accuracy 15.0%, cross entropy 2.310423\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-13\"\n",
      "INFO:tensorflow:Step #14: rate 0.001000, accuracy 24.0%, cross entropy 2.266146\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-14\"\n",
      "INFO:tensorflow:Step #15: rate 0.001000, accuracy 15.0%, cross entropy 2.433965\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-15\"\n",
      "INFO:tensorflow:Step #16: rate 0.001000, accuracy 19.0%, cross entropy 2.361516\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-16\"\n",
      "INFO:tensorflow:Step #17: rate 0.001000, accuracy 28.0%, cross entropy 2.265134\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-17\"\n",
      "INFO:tensorflow:Step #18: rate 0.001000, accuracy 23.0%, cross entropy 2.286622\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-18\"\n",
      "INFO:tensorflow:Step #19: rate 0.001000, accuracy 17.0%, cross entropy 2.345992\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-19\"\n",
      "INFO:tensorflow:Step #20: rate 0.001000, accuracy 18.0%, cross entropy 2.381654\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-20\"\n",
      "INFO:tensorflow:Step #21: rate 0.001000, accuracy 18.0%, cross entropy 2.361958\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-21\"\n",
      "INFO:tensorflow:Step #22: rate 0.001000, accuracy 18.0%, cross entropy 2.323692\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-22\"\n",
      "INFO:tensorflow:Step #23: rate 0.001000, accuracy 20.0%, cross entropy 2.319534\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-23\"\n",
      "INFO:tensorflow:Step #24: rate 0.001000, accuracy 13.0%, cross entropy 2.411629\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-24\"\n",
      "INFO:tensorflow:Step #25: rate 0.001000, accuracy 19.0%, cross entropy 2.230438\n",
      "INFO:tensorflow:Saving to \"../logs&checkpoint/conv/ckpt-25\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6ff732982429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/metal_geek/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-262499f30cde>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m     23\u001b[0m                   \u001b[0mstart_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_step_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                   \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_architecture\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                   summaries_dir=FLAGS.summaries_dir,args=extra_args)\n\u001b[0m",
      "\u001b[0;32m/home/metal_geek/Documents/GIT/Tensorflow_Audio_Recognition_Kaggle/src/libs/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(sess, logits, fingerprint_input, ground_truth_input, get_train_data, get_val_data, training_steps, learning_rate, eval_step_interval, logging_interval, start_checkpoint, checkpoint_interval, model_name, train_dir, summaries_dir, args)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# Pull the audio samples we'll use for training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# Modify here to pass whatever argument is required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mtrain_fingerprints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         train_summary, train_accuracy, cross_entropy_value, _, _ = sess.run(\n\u001b[1;32m    107\u001b[0m             [\n",
      "\u001b[0;32m<ipython-input-7-68a981505f34>\u001b[0m in \u001b[0;36mget_train_data\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      4\u001b[0m     train_fingerprints, train_ground_truth = audio_processor.get_data(\n\u001b[1;32m      5\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbackground_frequency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         background_volume, time_shift_samples, 'training', sess)\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_fingerprints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_ground_truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/metal_geek/Documents/GIT/Tensorflow_Audio_Recognition_Kaggle/src/libs/input_data.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, how_many, offset, model_settings, background_frequency, background_volume_range, time_shift, mode, sess)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeground_volume_placeholder_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# Run the graph to produce the output audio.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m       \u001b[0mlabel_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m       \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/metal_geek/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/metal_geek/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1105\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/metal_geek/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    399\u001b[0m   \u001b[0;31m# dict instead of doing it in the callers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_handles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m     \"\"\"Creates a fetch handler.\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.app.run(main=main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_checkpoint=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path=os.path.join(FLAGS.models_dir,model_architecture,'%s.pb'%os.path.basename(save_checkpoint))\n",
    "freeze.freeze_graph(FLAGS,model_architecture,save_checkpoint,save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
